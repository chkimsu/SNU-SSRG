{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kang/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:324: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/home/kang/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:359: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/home/kang/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:324: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/home/kang/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:359: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/home/kang/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:324: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/home/kang/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:359: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/home/kang/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:324: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/home/kang/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:359: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/home/kang/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:324: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/home/kang/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:359: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/home/kang/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:128: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "import random\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Merge\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back)]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back])\n",
    "    return numpy.array(dataX), numpy.array(dataY)\n",
    "\n",
    "corMat = pandas.read_csv('correlationmatrix.csv', engine='python')\n",
    "corMat = corMat.iloc[:,1:21]\n",
    "\n",
    "dataframe = pandas.read_csv('시뮬레이션 데이터.csv', engine='python')\n",
    "dataframe = dataframe.iloc[0:46,1:21]\n",
    "error_scores2= pandas.DataFrame(index=range(20),columns=[\"5~10년\",\"5~15년\",\"5~20년\",\"5~25년\",\"5~30년\",\"5~35년\"])\n",
    "\n",
    "for i in range(20):\n",
    "\tk=0\n",
    "\tdataframe2 = dataframe.iloc[:,i]\n",
    "\tdataset = dataframe2.values\n",
    "\tdataset = dataset.astype('float32')\n",
    "\tscaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\tdataset = scaler.fit_transform(dataset)\n",
    "\t\n",
    "\tdatasetcompare1 = (dataframe.iloc[:,corMat.iloc[i,1]]).values\n",
    "\tdatasetcompare1 = datasetcompare1.astype('float32')\n",
    "\tscalercompare1 = MinMaxScaler(feature_range=(0, 1))\n",
    "\tdatasetcompare1 = scalercompare1.fit_transform(datasetcompare1)\n",
    "\t\n",
    "\n",
    "\tdatasetcompare2 = (dataframe.iloc[:,corMat.iloc[i,2]]).values\n",
    "\tdatasetcompare2 = datasetcompare2.astype('float32')\n",
    "\tscalercompare2 = MinMaxScaler(feature_range=(0, 1))\n",
    "\tdatasetcompare2 = scalercompare2.fit_transform(datasetcompare2)\n",
    "\n",
    "\tdatasetcompare3 = (dataframe.iloc[:,corMat.iloc[i,3]]).values\n",
    "\tdatasetcompare3 = datasetcompare3.astype('float32')\n",
    "\tscalercompare3 = MinMaxScaler(feature_range=(0, 1))\n",
    "\tdatasetcompare3 = scalercompare3.fit_transform(datasetcompare3)\n",
    "\n",
    "\n",
    "\tdatasetcompare4 = (dataframe.iloc[:,corMat.iloc[i,4]]).values\n",
    "\tdatasetcompare4 = datasetcompare4.astype('float32')\n",
    "\tscalercompare4 = MinMaxScaler(feature_range=(0, 1))\n",
    "\tdatasetcompare4 = scalercompare4.fit_transform(datasetcompare4)\n",
    "\n",
    "\t\n",
    "\trepeats = 3\n",
    "\t\n",
    "\tfor j in [5,10,15,20,25,30]:\n",
    "\t\terror_scores = list()\n",
    "\t\tfor r in range(repeats):\n",
    "\t\t\tnumpy.random.seed(random.randrange(1,1000))\n",
    "\t\t\ttrain_size = j\n",
    "\t\t\ttest_size = len(dataset) - train_size\n",
    "\t\t\ttrain, test = dataset[0:train_size], dataset[train_size:len(dataset)]\n",
    "\t\t\tlook_back = 3\n",
    "\t\t\ttrainX, trainY = create_dataset(train, look_back)\n",
    "\t\t\ttestX, testY = create_dataset(test, look_back)\n",
    "\t\t\ttrainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "\t\t\ttestX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "\t\t\t\n",
    "\t\t\tfirst_model = Sequential()\n",
    "\t\t\tfirst_model.add(LSTM(4,input_shape=(1,look_back)))\n",
    "\t\t\tfirst_model.add(Dense(1))\n",
    "\t\t\t\n",
    "\t\t\t\n",
    "\t\t\ttraincompare1, testcompare1 = datasetcompare1[0:train_size], datasetcompare1[train_size:len(dataset)]\n",
    "\t\t\tlook_back = 3\n",
    "\t\t\ttrainXcompare1, trainYcompare1 = create_dataset(traincompare1, look_back)\n",
    "\t\t\ttestXcompare1, testYcompare1 = create_dataset(testcompare1, look_back)\n",
    "\t\t\ttrainXcompare1 = numpy.reshape(trainXcompare1, (trainXcompare1.shape[0], 1, trainXcompare1.shape[1]))\n",
    "\t\t\ttestXcompare1 = numpy.reshape(testXcompare1, (testXcompare1.shape[0], 1, testXcompare1.shape[1]))\n",
    "\t\t\t\n",
    "\t\t\tsecond_model = Sequential()\n",
    "\t\t\tsecond_model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "\t\t\tsecond_model.add(Dense(1))\n",
    "\t\t\t\n",
    "\t\t\t\n",
    "\t\t\ttraincompare2, testcompare2 = datasetcompare2[0:train_size], datasetcompare2[train_size:len(dataset)]\n",
    "\t\t\tlook_back = 3\n",
    "\t\t\ttrainXcompare2, trainYcompare2 = create_dataset(traincompare2, look_back)\n",
    "\t\t\ttestXcompare2, testYcompare2 = create_dataset(testcompare2, look_back)\n",
    "\t\t\ttrainXcompare2 = numpy.reshape(trainXcompare2, (trainXcompare2.shape[0], 1, trainXcompare2.shape[1]))\n",
    "\t\t\ttestXcompare2 = numpy.reshape(testXcompare2, (testXcompare2.shape[0], 1, testXcompare2.shape[1]))\n",
    "\t\t\t\n",
    "\t\t\tthird_model = Sequential()\n",
    "\t\t\tthird_model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "\t\t\tthird_model.add(Dense(1))\n",
    "\n",
    "\t\t\t\n",
    "\t\t\ttraincompare3, testcompare3 = datasetcompare3[0:train_size], datasetcompare3[train_size:len(dataset)]\n",
    "\t\t\tlook_back = 3\n",
    "\t\t\ttrainXcompare3, trainYcompare3 = create_dataset(traincompare3, look_back)\n",
    "\t\t\ttestXcompare3, testYcompare3 = create_dataset(testcompare3, look_back)\n",
    "\t\t\ttrainXcompare3 = numpy.reshape(trainXcompare3, (trainXcompare3.shape[0], 1, trainXcompare3.shape[1]))\n",
    "\t\t\ttestXcompare3 = numpy.reshape(testXcompare3, (testXcompare3.shape[0], 1, testXcompare3.shape[1]))\n",
    "\t\t\t\n",
    "\t\t\tfourth_model = Sequential()\n",
    "\t\t\tfourth_model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "\t\t\tfourth_model.add(Dense(1))\n",
    "\t\t\t\n",
    "\t\t\t\n",
    "\t\t\ttraincompare4, testcompare4 = datasetcompare4[0:train_size], datasetcompare4[train_size:len(dataset)]\n",
    "\t\t\tlook_back = 3\n",
    "\t\t\ttrainXcompare4, trainYcompare4 = create_dataset(traincompare4, look_back)\n",
    "\t\t\ttestXcompare4, testYcompare4 = create_dataset(testcompare4, look_back)\n",
    "\t\t\ttrainXcompare4 = numpy.reshape(trainXcompare4, (trainXcompare4.shape[0], 1, trainXcompare4.shape[1]))\n",
    "\t\t\ttestXcompare4 = numpy.reshape(testXcompare4, (testXcompare4.shape[0], 1, testXcompare4.shape[1]))\n",
    "\t\t\t\n",
    "\t\t\tfifth_model = Sequential()\n",
    "\t\t\tfifth_model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "\t\t\tfifth_model.add(Dense(1))\n",
    "\t\t\t\n",
    "\t\t\t\n",
    "\t\t\tmodel = Sequential()\n",
    "\t\t\tmodel.add(Merge([first_model, second_model,third_model,fourth_model,fifth_model], mode='concat'))\n",
    "\t\t\tmodel.add(Dense(1))\n",
    "\n",
    "\t\t\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\t\t\tmodel.fit([trainX,trainXcompare1,trainXcompare2,trainXcompare3,trainXcompare4], trainY, epochs=10, batch_size=1, verbose=2)\n",
    "\t\t\t\n",
    "\t\t\ttrainPredict = model.predict([trainX,trainXcompare1,trainXcompare2,trainXcompare3,trainXcompare4])\n",
    "\t\t\ttestPredict = model.predict([testX,testXcompare1,testXcompare2,testXcompare3,testXcompare4])\n",
    "\t\t\ttrainPredict = scaler.inverse_transform(trainPredict)\n",
    "\t\t\ttrainY = scaler.inverse_transform([trainY])\n",
    "\t\t\ttestPredict = scaler.inverse_transform(testPredict)\n",
    "\t\t\ttestY = scaler.inverse_transform([testY])\n",
    "\t\t\t\n",
    "\t\t\t\n",
    "\t\t\ttestScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "\t\t\terror_scores.append(testScore)\n",
    "\t\t\n",
    "\t\tresults = pandas.DataFrame()\n",
    "\t\tresults['rmse'] = error_scores\n",
    "\t\terror_scores2.iloc[i,k]=results.describe().iloc[1,0]\n",
    "\t\tk=k+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pandas.DataFrame((error_scores2.mean(axis=0))).iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error_scores2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
